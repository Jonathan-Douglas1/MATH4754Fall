---
title: "Lab#4"
author: "Jonathan Douglas"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Task 1: Set and get the working directory

Set and Find the WD

```{r}
setwd("/Users/jonathandouglas/MATH4753/FALL244753doug0080/Labs/Lab4")
getwd()
```

## Task 2: Read in the spruce dataset

```{r}
library(Intro2R)
library(s20x)
library(ggplot2)

#Read in the spruce dataset
spruce = Intro2R::spruce

#Print the head of the spruce dataset
head(spruce)
```

## Task 3:

#### Create Lowess Scatter plot

```{r}
library(s20x)

#Create the trendscatter plot
trendscatter(spruce$Height~spruce$BHDiameter, f = 0.5)
```

#### Create Linear model object

```{r}
#Create linear model
spruce.lm = with(spruce, lm(Height~BHDiameter))
#Find the residuals
height.res = residuals(spruce.lm)
#Find the fitted values
height.fit = fitted(spruce.lm)

#Plot the residuals vs fitted values
plot(height.fit, height.res, main = "Plot of Residuals vs Fitted Values")
```

#### Create Trendscatter of Residuals vs Fitted Values

```{r}
#Create the trendscatter plot of Residuals vs Fitted Values
trendscatter(height.res~height.fit, f = 0.5)
```

This graph shows that there is a trend similar to an upside down parabola when residuals are plotted with fitted values. This is a lot less linear than the fit found in the first graph.

#### Make Plot of Residuals

```{r}
plot(height.res, spruce$BHDiameter, main = "Plot of Residuals vs BHD")
```

#### Check for normality and shapiro wilk

```{r}
#Do Normal check with shapiro wilk
normcheck(spruce.lm, shapiro.wilk = TRUE)
```

The p-value from the Shapiro-Wilk test is 0.29. This shows that the the null hypothesis of a normally distributed dataset is confirmed.

#### Conclusion

I don't think that the straight line model is the best fit for this dataset because the plot of residuals vs fitted values still shows a signal, which means that there is a better model for this dataset.

## Task 4:

```{r}
#Create a quadratic model
quad.lm = with(spruce, lm(Height~BHDiameter + I(BHDiameter^2)))

#Create a new scatter plot
plot(spruce$Height ~ spruce$BHDiameter, main = "Height vs BHD with quadratic fit", xlab = "Breast Height Diameter (cm)", ylab = 
       "Height of Tree (m)", pch = 21, bg = "blue", cex = 1.2,
     xlim = c(0, 1.1 * max(spruce$BHDiameter)), ylim = 
       c(0, 1.1 * max(spruce$Height)))

#Or more general method
myplot=function(x){
 quad.lm$coef[1] +quad.lm$coef[2]*x  + quad.lm$coef[3]*x^2
} 
#Add the quadratic for to the plot
curve(myplot, lwd=2, col="steelblue",add=TRUE)
```

#### Create Plot of Residuals vs Fitted Values

```{r}
#Here is an easier way to make this plot that I accidentally discovered
plot(quad.lm, which = 1)
```

#Construct a QQ check

```{r}
#Do QQ test
normcheck(quad.lm, shapiro.wilk = TRUE)
```

The P-value of the shapiro wilk test here is 0.684, which strongly indicates a normally distributed dataset.

## Task 5:

#### Summarize quad.lm

```{r}
summary(quad.lm)
```

| Coefficient | Value    |
|-------------|----------|
| Beta0       | 0.861    |
| Beta1       | 1.4696   |
| Beta2       | -0.02746 |

#### Find the interval estimates
```{r}
#Calculate the interval estimates of the quadratic fit.
ciReg(quad.lm)
```

#### Use predict to find the expected height of the spruce trees
```{r}
pre_height = predict(quad.lm, data.frame(BHDiameter = c(15, 18, 20)))
cat("Quadratic: Expected height with 15 cm BHD:", pre_height[1], '\n')
cat("Expected height with 18 cm BHD:", pre_height[2], '\n')
cat("Expected height with 20 cm BHD:", pre_height[3])
```

#### Compare this with previous predictions
```{r}
pre_heightl = predict(spruce.lm, data.frame(BHDiameter = c(15, 18, 20)))
cat("Linear: Expected height with 15 cm BHD:", pre_heightl[1], '\n')
cat("Expected height with 18 cm BHD:", pre_heightl[2], '\n')
cat("Expected height with 20 cm BHD:", pre_heightl[3], '\n')

```

When comparing the two models, it is apparent that the quadratic model gives larger estimated heights for the same inputted breast height diameters. 

#### Calculate the residual sum of squares
```{r}
#This is the residual sum of squares.
RSS = sum((residuals(quad.lm))^2)
# Total sum of squares
TSS = sum((spruce$Height - mean(spruce$Height))^2)

# Calculate R-squared
R2 = 1 - (RSS / TSS)
cat("RSS from Quad:", R2,'\n')

RSSl = sum((residuals(spruce.lm))^2)
# Total sum of squares
TSSl = sum((spruce$Height - mean(spruce$Height))^2)
# Calculate R-squared
R2l = 1 - (RSSl / TSSl)
cat("RSS from Linear model:", R2l)
```

The R^2 is larger for the quadratic model than the linear one, indicating that this model is a better fit

#### Use the adjusted R^2 values
```{r}
#Calculate adjusted R-squared
linR2 = summary(spruce.lm)$adj.r.squared  # Adjusted R-squared for linear model
quadR2 = summary(quad.lm)$adj.r.squared    # Adjusted R-squared for quadratic model
cat("Linear Adj R^2:", linR2, '\n')
cat("Quadratic Adj R^2:", quadR2, '\n')
```

This calculation still shows that the quadratic model has the better R^2 value when compared to the linear model, and thus should be used here.

#### What does multiple R^2 mean in this case
The most variablility in height is explained by the first model because this implies that the growth is more random and doesn't follow a quadratic fit. 

#### Do Anova analysis
```{r}
#Compare models:
anova(spruce.lm,quad.lm)
```

This function shows that the residual sum of squares is smaller on the quadratic model, meaning it is more accuraute than the linear one. 

#### Calculate TSS, RSS, and MSS
```{r}
#This is the residual sum of squares.
RSS = sum((residuals(quad.lm))^2)
# Total sum of squares
TSS = sum((spruce$Height - mean(spruce$Height))^2)
#Mean sum of squares
MSS = TSS - RSS

#Print all these
cat("TSS:", TSS, " RSS:", RSS, " MSS:", MSS, '\n')
```

####Find MSS / TSS
```{r}
#FInd this value
cat("MSS/TSS:", MSS/TSS)
```


## Task 6:

#### Investigate unusual points 
```{r}
#Investigate unusual points
cooks20x(quad.lm)
```

The Cooks Distance is a measure of how important each point is for creating the fitted model. The higher the value of the cooks distance, the greater the effect changing that point will have on the fitted model.

This plot shows that there are 3 points have have a very large influence on the model that is created.

#### Remove the point with the largest cooks distance.
This point is located at index 24
```{r}
#Remove the 24th point, which has the highest influence on the model.
spruce2 = spruce[-24,]

#create the new model
quad2.lm = with(spruce2, lm(Height~BHDiameter + I(BHDiameter^2)))

print("Old Model")
summary(quad.lm)

print("New Model")
summary(quad2.lm)
```

The new model with the point removed has a higher R^2 value than the origional quadratic model, meaning that this new new model is a better fit for the data. The missing point was probably contributing a lot to the bad fit. 

## Task 7:

#### Show the equation for a fit with two segments in Latex
$$
y = \beta_{0} + \beta_{1} x + \beta_2 (x - x_k)I(x> x_k)
$$

When (x>xk), I = 1 and thus the B2 term exists, but when (x <= 0), the I function is 0. This is how different line segments are made. 

#### Recreate the plot shown in the lab document.
```{r}
#Create the piecewise linear fit
## piecewise linear model in R
## Model y = b0 + b1x + b2(x-xk)*(x>xk)
sp2.df=within(spruce, X<-(BHDiameter-18)*(BHDiameter>18)) # this makes a new variable and places it within the same df

lmp=lm(Height~BHDiameter + X,data=sp2.df)
tmp=summary(lmp)

myf = function(x,coef){
  coef[1]+coef[2]*(x) + coef[3]*(x-18)*(x-18>0)
}
plot(spruce,main="Piecewise regression")

curve(myf(x,coef=tmp$coefficients[,"Estimate"] ),add=TRUE, lwd=2,col="Blue")
abline(v=18)
text(18,16,paste("R sq.=",round(tmp$r.squared,4) ))

```

## Task 8: Create and test the R package
```{r}
#Import intro to R
library(FALL244753doug0080)

#Do a test call of my function, LinearFitPlot
linear_model = FALL244753doug0080::LinearFitPlot(spruce$BHDiameter, spruce$Height, title = "Test plot for Function", xaxislab = "BHD", yaxislab = "Height")

summary(linear_model)
```

#### Explaination:
Here, the function that I created is the LinearFitPlot function. This function takes a set of data doe the x and y axis and creates a linear model object for the data. This model is then plotted over the scatterplot of the dataset given for the x and y axis, and the graph is printed. The linear model object is then returned. 

#### Last 10 lines of check:
  Undefined global functions or variables:
    abline lm
  Consider adding
    importFrom("graphics", "abline")
    importFrom("stats", "lm")
  to your NAMESPACE file.

0 errors ✔ | 3 warnings ✖ | 3 notes ✖
Error: R CMD check found WARNINGs
Execution halted

Exited with status 1.



